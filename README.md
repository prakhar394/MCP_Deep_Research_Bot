# ğŸ§  MCP Research Assistant

A modular, verifiable, multi-agent research system using the **Model Context Protocol (MCP)**, OpenAI tools, semantic verification, arXiv retrieval, and FastAPI.

---

## ğŸš€ Overview

This project implements a **production-grade research agent** that can:

* Retrieve academic papers using MCP tools (`arxiv_search`, `web_search`, `fetch_paper`)
* Summarize them using an LLM
* Extract atomic factual claims
* Verify each claim using:

  * Semantic similarity
  * An NLI model (`deberta-large-mnli`)
  * Optional external search
* Iterate until a high-confidence answer is produced
* Serve everything over a clean **FastAPI API**

You get:

* Research retrieval
* Automated synthesis
* Structured verification
* Deterministic refinement
* Full logs
* Plug-and-play backend

---

## ğŸ—ï¸ System Architecture

```
User Query
    â†“
FastAPI (api.py)
    â†“
MCPResearchAssistant
    â†“
â”œâ”€â”€ MCPRetrieverAgent
â”‚     â””â”€â”€ arxiv_search, embeddings
â”œâ”€â”€ SummarizerAgent
â”‚     â””â”€â”€ openai summarization
â””â”€â”€ ThoroughMCPVerifier
      â”œâ”€â”€ semantic verification
      â”œâ”€â”€ NLI entailment
      â””â”€â”€ confidence scoring
    â†“
Final Verified Answer
```

---

## ğŸ“ Project Structure

```
mcp-research-assistant/
â”‚
â”œâ”€â”€ api.py                     # FastAPI app entrypoint
â”œâ”€â”€ main.py                    # CLI runner (optional)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md                  â† you are here
â”œâ”€â”€ venv/
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ base_agent.py
    â”‚   â”œâ”€â”€ summarizer.py
    â”‚   â”œâ”€â”€ mcp_retriever.py
    â”‚   â””â”€â”€ thorough_mcp_verifier.py
    â”‚
    â”œâ”€â”€ mcp/
    â”‚   â”œâ”€â”€ tool_definitions.py
    â”‚   â””â”€â”€ tool_executors.py
    â”‚
    â”œâ”€â”€ utils/
    â”‚   â”œâ”€â”€ logger.py
    â”‚   â””â”€â”€ cache.py
    â”‚
    â””â”€â”€ mcp_research_assistant.py
```

---

## ğŸ”§ Installation

### 1. Create and activate virtual environment

```bash
python3 -m venv venv
source venv/bin/activate
```

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

If you are missing loguru:

```bash
pip install loguru
```

---

## âš™ï¸ Environment Variables

Create `.env`:

```
OPENAI_API_KEY=your-key
TAVILY_API_KEY=your-key
```

---

## â–¶ï¸ Running the API

Because your FastAPI file is **in the project root** (`api.py`), start the server with:

```bash
python -m uvicorn api:app --reload
```

âœ” This ensures uvicorn uses your **virtualenv python** and does not try to import the wrong module.

### DO NOT run:

```bash
uvicorn api:app
```

because this will use the **Anaconda uvicorn**, not the venv one.

---

## â–¶ï¸ Running the CLI tool

```bash
python main.py
```

This will execute a full MCP query run:

* arxiv search â†’
* summarization â†’
* verification â†’
* final answer

---

## ğŸ” API Endpoints

### `POST /research`

Request:

```json
{
  "query": "What are recent advances in transformer efficiency?"
}
```

Response:

```json
{
  "answer": "... final verified summary ...",
  "confidence": 0.81,
  "sources": [...],
  "verification_details": {...}
}
```

---

## ğŸ§ª How Verification Works

Verification is hybrid:

### 1. **Semantic similarity**

* Claims compared to paper abstracts
* High similarity â†’ more confidence

### 2. **NLI model**

* `microsoft/deberta-large-mnli`
* Determines entailment/contradiction/neutral

### 3. **Aggregate confidence**

Final confidence:

```
0.5 * semantic_score + 0.5 * NLI_score
```

No external web search â†’ fully deterministic, grounded in provided papers.

---

## ğŸ§© Features

* âœ” MCP tool framework
* âœ” arxiv retrieval
* âœ” LLM summarizer
* âœ” claim extractor
* âœ” semantic verification
* âœ” NLI verification
* âœ” FastAPI interface
* âœ” CLI interface
* âœ” Caching layer
* âœ” Logging with Loguru
* âœ” Modular agent architecture

---
